{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cQJDMWGUyx7",
        "outputId": "001ee132-664c-42b2-8d30-7718f4123651"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Mar 17 18:03:28 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla V100-SXM2-16GB           Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   46C    P0              27W / 300W |      0MiB / 16384MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0ln89jnVyCb",
        "outputId": "8a0bfdd4-b926-48a6-f1a9-dc34f5097061"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/htootayzaaung/Planets_and_Moons.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXrITb-9V1PG",
        "outputId": "ed7e8847-ee79-4cb3-e129-93ccf04e81aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Planets_and_Moons'...\n",
            "remote: Enumerating objects: 1648, done.\u001b[K\n",
            "remote: Counting objects: 100% (1648/1648), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1648/1648), done.\u001b[K\n",
            "remote: Total 1648 (delta 0), reused 1648 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (1648/1648), 19.75 MiB | 23.96 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mv2nq61V6yA",
        "outputId": "caef8f38-1d68-4a18-f91d-4f6282c67044"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Planets_and_Moons  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd Planets_and_Moons"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6sS6EimWV81O",
        "outputId": "b6f525d3-0f05-4724-a221-6ee13f9d2d91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Planets_and_Moons\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJRzbRTtWH37",
        "outputId": "912d5d64-5a07-4f82-b92c-303f06ecac0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Earth  Jupiter\tMakeMake  Mars\tMercury  Moon  Neptune\tPluto  Saturn  train.py  Uranus  Venus\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 train.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rItr-qw5WJ0F",
        "outputId": "4bd85eb9-708d-4910-fcb8-d94b5fe695f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Epoch 1/10\n",
            "Epoch: 1, Batch: 1, Loss: 3.4167280197143555\n",
            "Epoch: 1, Batch: 11, Loss: 0.17941614985466003\n",
            "Epoch: 1, Batch: 21, Loss: 0.1432376205921173\n",
            "Epoch: 1, Batch: 31, Loss: 0.10724997520446777\n",
            "Epoch: 1, Batch: 41, Loss: 0.13492359220981598\n",
            "Epoch: 1, Batch: 51, Loss: 0.0736541599035263\n",
            "Epoch: 1, Batch: 61, Loss: 0.09129828214645386\n",
            "Epoch: 1, Batch: 71, Loss: 0.08840196579694748\n",
            "Epoch: 1, Batch: 81, Loss: 0.08141002058982849\n",
            "Epoch: 1, Batch: 91, Loss: 0.0773044154047966\n",
            "Epoch: 1, Batch: 101, Loss: 0.0732697993516922\n",
            "Epoch: 1, Batch: 111, Loss: 0.07760025560855865\n",
            "Epoch: 1, Batch: 121, Loss: 0.09043733030557632\n",
            "Epoch: 1, Batch: 131, Loss: 0.06911682337522507\n",
            "Epoch: 1, Batch: 141, Loss: 0.06767738610506058\n",
            "Epoch: 1, Batch: 151, Loss: 0.06922134757041931\n",
            "Epoch: 1, Batch: 161, Loss: 0.05745656043291092\n",
            "Epoch: 1, Batch: 171, Loss: 0.05698004364967346\n",
            "Epoch: 1, Batch: 181, Loss: 0.0785096287727356\n",
            "Epoch: 1, Batch: 191, Loss: 0.0723193883895874\n",
            "Epoch: 1, Batch: 201, Loss: 0.05076729506254196\n",
            "Epoch: 1, Batch: 211, Loss: 0.04244586080312729\n",
            "Epoch: 1, Batch: 221, Loss: 0.06543238461017609\n",
            "Epoch: 1, Batch: 231, Loss: 0.06168310344219208\n",
            "Epoch: 1, Batch: 241, Loss: 0.049789488315582275\n",
            "Epoch: 1, Batch: 251, Loss: 0.05807330086827278\n",
            "Epoch: 1, Batch: 261, Loss: 0.062073349952697754\n",
            "Epoch: 1, Batch: 271, Loss: 0.07325468957424164\n",
            "Epoch: 1, Batch: 281, Loss: 0.05663738027215004\n",
            "Epoch: 1, Batch: 291, Loss: 0.058116063475608826\n",
            "Epoch: 1, Batch: 301, Loss: 0.05239511653780937\n",
            "Epoch: 1, Batch: 311, Loss: 0.08099924027919769\n",
            "Epoch: 1, Batch: 321, Loss: 0.048655565828084946\n",
            "Epoch: 1, Batch: 331, Loss: 0.06062925234436989\n",
            "Epoch: 1, Batch: 341, Loss: 0.06486428529024124\n",
            "Epoch: 1, Batch: 351, Loss: 0.03983427956700325\n",
            "Epoch: 1, Batch: 361, Loss: 0.05686333030462265\n",
            "Epoch: 1, Batch: 371, Loss: 0.053890421986579895\n",
            "Epoch: 1, Batch: 381, Loss: 0.05096564069390297\n",
            "Epoch: 1, Batch: 391, Loss: 0.04814726859331131\n",
            "Epoch: 1, Batch: 401, Loss: 0.05058058723807335\n",
            "Epoch: 1, Batch: 411, Loss: 0.038444750010967255\n",
            "Epoch: 1, Batch: 421, Loss: 0.04016198590397835\n",
            "Epoch: 1, Batch: 431, Loss: 0.050353147089481354\n",
            "Epoch: 1, Batch: 441, Loss: 0.04546056687831879\n",
            "Epoch: 1, Batch: 451, Loss: 0.023521751165390015\n",
            "Epoch: 1, Batch: 461, Loss: 0.053991980850696564\n",
            "Epoch: 1, Batch: 471, Loss: 0.036397017538547516\n",
            "Epoch: 1, Batch: 481, Loss: 0.02741577848792076\n",
            "Epoch: 1, Batch: 491, Loss: 0.04112424701452255\n",
            "Epoch: 1, Batch: 501, Loss: 0.028390660881996155\n",
            "Epoch: 1, Batch: 511, Loss: 0.04781259968876839\n",
            "Epoch: 1, Batch: 521, Loss: 0.04362545162439346\n",
            "Epoch: 1, Batch: 531, Loss: 0.03275664150714874\n",
            "Epoch: 1, Batch: 541, Loss: 0.05267356336116791\n",
            "Epoch: 1, Batch: 551, Loss: 0.030697358772158623\n",
            "Epoch: 1, Batch: 561, Loss: 0.03513294458389282\n",
            "Epoch: 1, Batch: 571, Loss: 0.05271085724234581\n",
            "Epoch: 1, Batch: 581, Loss: 0.027225486934185028\n",
            "Epoch: 1, Batch: 591, Loss: 0.03762996196746826\n",
            "Epoch: 1, Batch: 601, Loss: 0.03453828766942024\n",
            "Epoch: 1, Batch: 611, Loss: 0.03169845789670944\n",
            "Epoch: 1, Batch: 621, Loss: 0.03127273917198181\n",
            "Epoch: 1, Batch: 631, Loss: 0.06373095512390137\n",
            "Epoch: 1, Batch: 641, Loss: 0.03479180857539177\n",
            "Epoch: 1, Batch: 651, Loss: 0.04039909690618515\n",
            "Epoch: 1, Batch: 661, Loss: 0.053864870220422745\n",
            "Epoch: 1, Batch: 671, Loss: 0.043492890894412994\n",
            "Epoch: 1, Batch: 681, Loss: 0.024408409371972084\n",
            "Epoch: 1, Batch: 691, Loss: 0.02755056321620941\n",
            "Epoch: 1, Batch: 701, Loss: 0.0377640500664711\n",
            "Epoch: 1, Batch: 711, Loss: 0.051366712898015976\n",
            "Epoch: 1, Batch: 721, Loss: 0.0304368007928133\n",
            "Epoch: 1, Batch: 731, Loss: 0.030184997245669365\n",
            "Epoch: 1, Batch: 741, Loss: 0.02461855858564377\n",
            "Epoch: 1, Batch: 751, Loss: 0.0433509461581707\n",
            "Epoch: 1, Batch: 761, Loss: 0.03060649149119854\n",
            "Epoch: 1, Batch: 771, Loss: 0.04224253445863724\n",
            "Epoch: 1, Batch: 781, Loss: 0.03642423823475838\n",
            "Epoch: 1, Batch: 791, Loss: 0.04325792193412781\n",
            "Epoch: 1, Batch: 801, Loss: 0.02870403602719307\n",
            "Epoch: 1, Batch: 811, Loss: 0.04059829190373421\n",
            "Starting Epoch 2/10\n",
            "Epoch: 2, Batch: 1, Loss: 0.03462469205260277\n",
            "Epoch: 2, Batch: 11, Loss: 0.045323267579078674\n",
            "Epoch: 2, Batch: 21, Loss: 0.0318683385848999\n",
            "Epoch: 2, Batch: 31, Loss: 0.021987568587064743\n",
            "Epoch: 2, Batch: 41, Loss: 0.027591846883296967\n",
            "Epoch: 2, Batch: 51, Loss: 0.03203690052032471\n",
            "Epoch: 2, Batch: 61, Loss: 0.03755960613489151\n",
            "Epoch: 2, Batch: 71, Loss: 0.015026343986392021\n",
            "Epoch: 2, Batch: 81, Loss: 0.01994166523218155\n",
            "Epoch: 2, Batch: 91, Loss: 0.02652069739997387\n",
            "Epoch: 2, Batch: 101, Loss: 0.03457269072532654\n",
            "Epoch: 2, Batch: 111, Loss: 0.04353830963373184\n",
            "Epoch: 2, Batch: 121, Loss: 0.03384615108370781\n",
            "Epoch: 2, Batch: 131, Loss: 0.0216536745429039\n",
            "Epoch: 2, Batch: 141, Loss: 0.02614496275782585\n",
            "Epoch: 2, Batch: 151, Loss: 0.020736876875162125\n",
            "Epoch: 2, Batch: 161, Loss: 0.01806647703051567\n",
            "Epoch: 2, Batch: 171, Loss: 0.032321102917194366\n",
            "Epoch: 2, Batch: 181, Loss: 0.00981791503727436\n",
            "Epoch: 2, Batch: 191, Loss: 0.021558042615652084\n",
            "Epoch: 2, Batch: 201, Loss: 0.014765419065952301\n",
            "Epoch: 2, Batch: 211, Loss: 0.020080838352441788\n",
            "Epoch: 2, Batch: 221, Loss: 0.01343926414847374\n",
            "Epoch: 2, Batch: 231, Loss: 0.025469526648521423\n",
            "Epoch: 2, Batch: 241, Loss: 0.019601471722126007\n",
            "Epoch: 2, Batch: 251, Loss: 0.02066158875823021\n",
            "Epoch: 2, Batch: 261, Loss: 0.031701523810625076\n",
            "Epoch: 2, Batch: 271, Loss: 0.0240473635494709\n",
            "Epoch: 2, Batch: 281, Loss: 0.04154817759990692\n",
            "Epoch: 2, Batch: 291, Loss: 0.02627865970134735\n",
            "Epoch: 2, Batch: 301, Loss: 0.016898008063435555\n",
            "Epoch: 2, Batch: 311, Loss: 0.01391630806028843\n",
            "Epoch: 2, Batch: 321, Loss: 0.012259751558303833\n",
            "Epoch: 2, Batch: 331, Loss: 0.016718106344342232\n",
            "Epoch: 2, Batch: 341, Loss: 0.032210856676101685\n",
            "Epoch: 2, Batch: 351, Loss: 0.030122114345431328\n",
            "Epoch: 2, Batch: 361, Loss: 0.018845105543732643\n",
            "Epoch: 2, Batch: 371, Loss: 0.031702037900686264\n",
            "Epoch: 2, Batch: 381, Loss: 0.01685682125389576\n",
            "Epoch: 2, Batch: 391, Loss: 0.01613622158765793\n",
            "Epoch: 2, Batch: 401, Loss: 0.019446922466158867\n",
            "Epoch: 2, Batch: 411, Loss: 0.024297738447785378\n",
            "Epoch: 2, Batch: 421, Loss: 0.01936648041009903\n",
            "Epoch: 2, Batch: 431, Loss: 0.009581747464835644\n",
            "Epoch: 2, Batch: 441, Loss: 0.019626399502158165\n",
            "Epoch: 2, Batch: 451, Loss: 0.012097236700356007\n",
            "Epoch: 2, Batch: 461, Loss: 0.017777735367417336\n",
            "Epoch: 2, Batch: 471, Loss: 0.015940196812152863\n",
            "Epoch: 2, Batch: 481, Loss: 0.014811752364039421\n",
            "Epoch: 2, Batch: 491, Loss: 0.013206928968429565\n",
            "Epoch: 2, Batch: 501, Loss: 0.014282360672950745\n",
            "Epoch: 2, Batch: 511, Loss: 0.018003173172473907\n",
            "Epoch: 2, Batch: 521, Loss: 0.01570432074368\n",
            "Epoch: 2, Batch: 531, Loss: 0.030233995988965034\n",
            "Epoch: 2, Batch: 541, Loss: 0.022890517488121986\n",
            "Epoch: 2, Batch: 551, Loss: 0.020103437826037407\n",
            "Epoch: 2, Batch: 561, Loss: 0.016561895608901978\n",
            "Epoch: 2, Batch: 571, Loss: 0.03503326326608658\n",
            "Epoch: 2, Batch: 581, Loss: 0.014568738639354706\n",
            "Epoch: 2, Batch: 591, Loss: 0.01939803920686245\n",
            "Epoch: 2, Batch: 601, Loss: 0.02095867320895195\n",
            "Epoch: 2, Batch: 611, Loss: 0.016519147902727127\n",
            "Epoch: 2, Batch: 621, Loss: 0.01680155284702778\n",
            "Epoch: 2, Batch: 631, Loss: 0.01048283837735653\n",
            "Epoch: 2, Batch: 641, Loss: 0.016110476106405258\n",
            "Epoch: 2, Batch: 651, Loss: 0.030192628502845764\n",
            "Epoch: 2, Batch: 661, Loss: 0.022149112075567245\n",
            "Epoch: 2, Batch: 671, Loss: 0.049556925892829895\n",
            "Epoch: 2, Batch: 681, Loss: 0.029063526540994644\n",
            "Epoch: 2, Batch: 691, Loss: 0.011927603743970394\n",
            "Epoch: 2, Batch: 701, Loss: 0.017143871635198593\n",
            "Epoch: 2, Batch: 711, Loss: 0.02636244148015976\n",
            "Epoch: 2, Batch: 721, Loss: 0.009604396298527718\n",
            "Epoch: 2, Batch: 731, Loss: 0.0217280313372612\n",
            "Epoch: 2, Batch: 741, Loss: 0.01937022991478443\n",
            "Epoch: 2, Batch: 751, Loss: 0.017251700162887573\n",
            "Epoch: 2, Batch: 761, Loss: 0.021652305498719215\n",
            "Epoch: 2, Batch: 771, Loss: 0.01641499437391758\n",
            "Epoch: 2, Batch: 781, Loss: 0.010029735043644905\n",
            "Epoch: 2, Batch: 791, Loss: 0.01308467797935009\n",
            "Epoch: 2, Batch: 801, Loss: 0.016537455841898918\n",
            "Epoch: 2, Batch: 811, Loss: 0.011319639161229134\n",
            "Starting Epoch 3/10\n",
            "Epoch: 3, Batch: 1, Loss: 0.014002544805407524\n",
            "Epoch: 3, Batch: 11, Loss: 0.02046653814613819\n",
            "Epoch: 3, Batch: 21, Loss: 0.012647212482988834\n",
            "Epoch: 3, Batch: 31, Loss: 0.021864335983991623\n",
            "Epoch: 3, Batch: 41, Loss: 0.0071110837161540985\n",
            "Epoch: 3, Batch: 51, Loss: 0.014294796623289585\n",
            "Epoch: 3, Batch: 61, Loss: 0.016943462193012238\n",
            "Epoch: 3, Batch: 71, Loss: 0.022910356521606445\n",
            "Epoch: 3, Batch: 81, Loss: 0.013596739619970322\n",
            "Epoch: 3, Batch: 91, Loss: 0.009325332939624786\n",
            "Epoch: 3, Batch: 101, Loss: 0.012296284548938274\n",
            "Epoch: 3, Batch: 111, Loss: 0.011391585692763329\n",
            "Epoch: 3, Batch: 121, Loss: 0.011641036719083786\n",
            "Epoch: 3, Batch: 131, Loss: 0.015296285971999168\n",
            "Epoch: 3, Batch: 141, Loss: 0.011870738118886948\n",
            "Epoch: 3, Batch: 151, Loss: 0.007670329883694649\n",
            "Epoch: 3, Batch: 161, Loss: 0.00913497619330883\n",
            "Epoch: 3, Batch: 171, Loss: 0.007224015425890684\n",
            "Epoch: 3, Batch: 181, Loss: 0.021878838539123535\n",
            "Epoch: 3, Batch: 191, Loss: 0.007005577441304922\n",
            "Epoch: 3, Batch: 201, Loss: 0.010531865060329437\n",
            "Epoch: 3, Batch: 211, Loss: 0.01425999402999878\n",
            "Epoch: 3, Batch: 221, Loss: 0.011138005182147026\n",
            "Epoch: 3, Batch: 231, Loss: 0.007672625593841076\n",
            "Epoch: 3, Batch: 241, Loss: 0.013378890231251717\n",
            "Epoch: 3, Batch: 251, Loss: 0.009946063160896301\n",
            "Epoch: 3, Batch: 261, Loss: 0.015089575201272964\n",
            "Epoch: 3, Batch: 271, Loss: 0.009683257900178432\n",
            "Epoch: 3, Batch: 281, Loss: 0.014127136208117008\n",
            "Epoch: 3, Batch: 291, Loss: 0.016288476064801216\n",
            "Epoch: 3, Batch: 301, Loss: 0.007137676235288382\n",
            "Epoch: 3, Batch: 311, Loss: 0.011662207543849945\n",
            "Epoch: 3, Batch: 321, Loss: 0.016682565212249756\n",
            "Epoch: 3, Batch: 331, Loss: 0.004149525426328182\n",
            "Epoch: 3, Batch: 341, Loss: 0.008662883192300797\n",
            "Epoch: 3, Batch: 351, Loss: 0.009158098138868809\n",
            "Epoch: 3, Batch: 361, Loss: 0.003996731713414192\n",
            "Epoch: 3, Batch: 371, Loss: 0.00432167062535882\n",
            "Epoch: 3, Batch: 381, Loss: 0.014664972200989723\n",
            "Epoch: 3, Batch: 391, Loss: 0.014091755263507366\n",
            "Epoch: 3, Batch: 401, Loss: 0.010760759934782982\n",
            "Epoch: 3, Batch: 411, Loss: 0.007566259242594242\n",
            "Epoch: 3, Batch: 421, Loss: 0.007794502656906843\n",
            "Epoch: 3, Batch: 431, Loss: 0.008483704179525375\n",
            "Epoch: 3, Batch: 441, Loss: 0.0045954035595059395\n",
            "Epoch: 3, Batch: 451, Loss: 0.010452075861394405\n",
            "Epoch: 3, Batch: 461, Loss: 0.007234932389110327\n",
            "Epoch: 3, Batch: 471, Loss: 0.013624249957501888\n",
            "Epoch: 3, Batch: 481, Loss: 0.008275505155324936\n",
            "Epoch: 3, Batch: 491, Loss: 0.01107191201299429\n",
            "Epoch: 3, Batch: 501, Loss: 0.008026573807001114\n",
            "Epoch: 3, Batch: 511, Loss: 0.00820584874600172\n",
            "Epoch: 3, Batch: 521, Loss: 0.008702035993337631\n",
            "Epoch: 3, Batch: 531, Loss: 0.008249207399785519\n",
            "Epoch: 3, Batch: 541, Loss: 0.010137843899428844\n",
            "Epoch: 3, Batch: 551, Loss: 0.005063222721219063\n",
            "Epoch: 3, Batch: 561, Loss: 0.012380163185298443\n",
            "Epoch: 3, Batch: 571, Loss: 0.006196451839059591\n",
            "Epoch: 3, Batch: 581, Loss: 0.015196496620774269\n",
            "Epoch: 3, Batch: 591, Loss: 0.005412666127085686\n",
            "Epoch: 3, Batch: 601, Loss: 0.008625662885606289\n",
            "Epoch: 3, Batch: 611, Loss: 0.021163735538721085\n",
            "Epoch: 3, Batch: 621, Loss: 0.009968403726816177\n",
            "Epoch: 3, Batch: 631, Loss: 0.006478490307927132\n",
            "Epoch: 3, Batch: 641, Loss: 0.02694077044725418\n",
            "Epoch: 3, Batch: 651, Loss: 0.010237788781523705\n",
            "Epoch: 3, Batch: 661, Loss: 0.005249371752142906\n",
            "Epoch: 3, Batch: 671, Loss: 0.009137568064033985\n",
            "Epoch: 3, Batch: 681, Loss: 0.0129000935703516\n",
            "Epoch: 3, Batch: 691, Loss: 0.010984550230205059\n",
            "Epoch: 3, Batch: 701, Loss: 0.0058826664462685585\n",
            "Epoch: 3, Batch: 711, Loss: 0.0057769231498241425\n",
            "Epoch: 3, Batch: 721, Loss: 0.010413257405161858\n",
            "Epoch: 3, Batch: 731, Loss: 0.005262428894639015\n",
            "Epoch: 3, Batch: 741, Loss: 0.0067418841645121574\n",
            "Epoch: 3, Batch: 751, Loss: 0.006556717213243246\n",
            "Epoch: 3, Batch: 761, Loss: 0.006493987049907446\n",
            "Epoch: 3, Batch: 771, Loss: 0.010920905508100986\n",
            "Epoch: 3, Batch: 781, Loss: 0.006143609061837196\n",
            "Epoch: 3, Batch: 791, Loss: 0.005745511967688799\n",
            "Epoch: 3, Batch: 801, Loss: 0.015842221677303314\n",
            "Epoch: 3, Batch: 811, Loss: 0.014897373504936695\n",
            "Starting Epoch 4/10\n",
            "Epoch: 4, Batch: 1, Loss: 0.010711760260164738\n",
            "Epoch: 4, Batch: 11, Loss: 0.005908393766731024\n",
            "Epoch: 4, Batch: 21, Loss: 0.004660089500248432\n",
            "Epoch: 4, Batch: 31, Loss: 0.004103758372366428\n",
            "Epoch: 4, Batch: 41, Loss: 0.003864881582558155\n",
            "Epoch: 4, Batch: 51, Loss: 0.0036392996553331614\n",
            "Epoch: 4, Batch: 61, Loss: 0.003969633486121893\n",
            "Epoch: 4, Batch: 71, Loss: 0.004705262370407581\n",
            "Epoch: 4, Batch: 81, Loss: 0.0020743838977068663\n",
            "Epoch: 4, Batch: 91, Loss: 0.0038483995012938976\n",
            "Epoch: 4, Batch: 101, Loss: 0.004508917685598135\n",
            "Epoch: 4, Batch: 111, Loss: 0.003934692125767469\n",
            "Epoch: 4, Batch: 121, Loss: 0.005466918461024761\n",
            "Epoch: 4, Batch: 131, Loss: 0.006184054538607597\n",
            "Epoch: 4, Batch: 141, Loss: 0.006979158613830805\n",
            "Epoch: 4, Batch: 151, Loss: 0.0033247012179344893\n",
            "Epoch: 4, Batch: 161, Loss: 0.009871359914541245\n",
            "Epoch: 4, Batch: 171, Loss: 0.0017344462685286999\n",
            "Epoch: 4, Batch: 181, Loss: 0.0020535143557935953\n",
            "Epoch: 4, Batch: 191, Loss: 0.0029884250834584236\n",
            "Epoch: 4, Batch: 201, Loss: 0.0028064486104995012\n",
            "Epoch: 4, Batch: 211, Loss: 0.003450043499469757\n",
            "Epoch: 4, Batch: 221, Loss: 0.003165422473102808\n",
            "Epoch: 4, Batch: 231, Loss: 0.0025253468193113804\n",
            "Epoch: 4, Batch: 241, Loss: 0.0037540807388722897\n",
            "Epoch: 4, Batch: 251, Loss: 0.0023141310084611177\n",
            "Epoch: 4, Batch: 261, Loss: 0.003495552809908986\n",
            "Epoch: 4, Batch: 271, Loss: 0.0037474886048585176\n",
            "Epoch: 4, Batch: 281, Loss: 0.00358756585046649\n",
            "Epoch: 4, Batch: 291, Loss: 0.008802919648587704\n",
            "Epoch: 4, Batch: 301, Loss: 0.009090159088373184\n",
            "Epoch: 4, Batch: 311, Loss: 0.01062719151377678\n",
            "Epoch: 4, Batch: 321, Loss: 0.005424331407994032\n",
            "Epoch: 4, Batch: 331, Loss: 0.0062986924313008785\n",
            "Epoch: 4, Batch: 341, Loss: 0.006447583436965942\n",
            "Epoch: 4, Batch: 351, Loss: 0.007247581612318754\n",
            "Epoch: 4, Batch: 361, Loss: 0.006452774163335562\n",
            "Epoch: 4, Batch: 371, Loss: 0.002629470080137253\n",
            "Epoch: 4, Batch: 381, Loss: 0.01219095941632986\n",
            "Epoch: 4, Batch: 391, Loss: 0.0022578879725188017\n",
            "Epoch: 4, Batch: 401, Loss: 0.0038890151772648096\n",
            "Epoch: 4, Batch: 411, Loss: 0.0028943712823092937\n",
            "Epoch: 4, Batch: 421, Loss: 0.006083248648792505\n",
            "Epoch: 4, Batch: 431, Loss: 0.00397837208583951\n",
            "Epoch: 4, Batch: 441, Loss: 0.0035858447663486004\n",
            "Epoch: 4, Batch: 451, Loss: 0.0017932080663740635\n",
            "Epoch: 4, Batch: 461, Loss: 0.0023157033137977123\n",
            "Epoch: 4, Batch: 471, Loss: 0.0022707751486450434\n",
            "Epoch: 4, Batch: 481, Loss: 0.004673841875046492\n",
            "Epoch: 4, Batch: 491, Loss: 0.007055469788610935\n",
            "Epoch: 4, Batch: 501, Loss: 0.006428955122828484\n",
            "Epoch: 4, Batch: 511, Loss: 0.005493794102221727\n",
            "Epoch: 4, Batch: 521, Loss: 0.004857106599956751\n",
            "Epoch: 4, Batch: 531, Loss: 0.004005969502031803\n",
            "Epoch: 4, Batch: 541, Loss: 0.003954172600060701\n",
            "Epoch: 4, Batch: 551, Loss: 0.002356677083298564\n",
            "Epoch: 4, Batch: 561, Loss: 0.0036149260122328997\n",
            "Epoch: 4, Batch: 571, Loss: 0.0024198233149945736\n",
            "Epoch: 4, Batch: 581, Loss: 0.003040268551558256\n",
            "Epoch: 4, Batch: 591, Loss: 0.004173245746642351\n",
            "Epoch: 4, Batch: 601, Loss: 0.0033765919506549835\n",
            "Epoch: 4, Batch: 611, Loss: 0.006244803313165903\n",
            "Epoch: 4, Batch: 621, Loss: 0.005815952084958553\n",
            "Epoch: 4, Batch: 631, Loss: 0.0021562078036367893\n",
            "Epoch: 4, Batch: 641, Loss: 0.002669735811650753\n",
            "Epoch: 4, Batch: 651, Loss: 0.0027933018282055855\n",
            "Epoch: 4, Batch: 661, Loss: 0.002957345452159643\n",
            "Epoch: 4, Batch: 671, Loss: 0.0028862450271844864\n",
            "Epoch: 4, Batch: 681, Loss: 0.004075016360729933\n",
            "Epoch: 4, Batch: 691, Loss: 0.004172125831246376\n",
            "Epoch: 4, Batch: 701, Loss: 0.004619890823960304\n",
            "Epoch: 4, Batch: 711, Loss: 0.002868573646992445\n",
            "Epoch: 4, Batch: 721, Loss: 0.002450421452522278\n",
            "Epoch: 4, Batch: 731, Loss: 0.002455292269587517\n",
            "Epoch: 4, Batch: 741, Loss: 0.0053460425697267056\n",
            "Epoch: 4, Batch: 751, Loss: 0.004644271917641163\n",
            "Epoch: 4, Batch: 761, Loss: 0.0033320626243948936\n",
            "Epoch: 4, Batch: 771, Loss: 0.002661935519427061\n",
            "Epoch: 4, Batch: 781, Loss: 0.005419878754764795\n",
            "Epoch: 4, Batch: 791, Loss: 0.0017421229276806116\n",
            "Epoch: 4, Batch: 801, Loss: 0.001791603397578001\n",
            "Epoch: 4, Batch: 811, Loss: 0.0037473603151738644\n",
            "Starting Epoch 5/10\n",
            "Epoch: 5, Batch: 1, Loss: 0.004803033079952002\n",
            "Epoch: 5, Batch: 11, Loss: 0.0030860912520438433\n",
            "Epoch: 5, Batch: 21, Loss: 0.005363319534808397\n",
            "Epoch: 5, Batch: 31, Loss: 0.0027988457586616278\n",
            "Epoch: 5, Batch: 41, Loss: 0.005436471663415432\n",
            "Epoch: 5, Batch: 51, Loss: 0.0039353761821985245\n",
            "Epoch: 5, Batch: 61, Loss: 0.0035581900738179684\n",
            "Epoch: 5, Batch: 71, Loss: 0.0044241975992918015\n",
            "Epoch: 5, Batch: 81, Loss: 0.001965938601642847\n",
            "Epoch: 5, Batch: 91, Loss: 0.004685179330408573\n",
            "Epoch: 5, Batch: 101, Loss: 0.006026822607964277\n",
            "Epoch: 5, Batch: 111, Loss: 0.0034526188392192125\n",
            "Epoch: 5, Batch: 121, Loss: 0.0035172486677765846\n",
            "Epoch: 5, Batch: 131, Loss: 0.004707413725554943\n",
            "Epoch: 5, Batch: 141, Loss: 0.0021436172537505627\n",
            "Epoch: 5, Batch: 151, Loss: 0.003730261465534568\n",
            "Epoch: 5, Batch: 161, Loss: 0.0020417238119989634\n",
            "Epoch: 5, Batch: 171, Loss: 0.003224927233532071\n",
            "Epoch: 5, Batch: 181, Loss: 0.0030369351152330637\n",
            "Epoch: 5, Batch: 191, Loss: 0.002193052787333727\n",
            "Epoch: 5, Batch: 201, Loss: 0.002067296765744686\n",
            "Epoch: 5, Batch: 211, Loss: 0.007776371203362942\n",
            "Epoch: 5, Batch: 221, Loss: 0.003398747416213155\n",
            "Epoch: 5, Batch: 231, Loss: 0.0016749206697568297\n",
            "Epoch: 5, Batch: 241, Loss: 0.00551521684974432\n",
            "Epoch: 5, Batch: 251, Loss: 0.002415109658613801\n",
            "Epoch: 5, Batch: 261, Loss: 0.005464860238134861\n",
            "Epoch: 5, Batch: 271, Loss: 0.003732262412086129\n",
            "Epoch: 5, Batch: 281, Loss: 0.0017407784471288323\n",
            "Epoch: 5, Batch: 291, Loss: 0.0039316946640610695\n",
            "Epoch: 5, Batch: 301, Loss: 0.004236201290041208\n",
            "Epoch: 5, Batch: 311, Loss: 0.0024348848965018988\n",
            "Epoch: 5, Batch: 321, Loss: 0.0025139644276350737\n",
            "Epoch: 5, Batch: 331, Loss: 0.0025789556093513966\n",
            "Epoch: 5, Batch: 341, Loss: 0.005225516855716705\n",
            "Epoch: 5, Batch: 351, Loss: 0.0048633418045938015\n",
            "Epoch: 5, Batch: 361, Loss: 0.0017052573384717107\n",
            "Epoch: 5, Batch: 371, Loss: 0.0033654202707111835\n",
            "Epoch: 5, Batch: 381, Loss: 0.005240485072135925\n",
            "Epoch: 5, Batch: 391, Loss: 0.001581073272973299\n",
            "Epoch: 5, Batch: 401, Loss: 0.003316975897178054\n",
            "Epoch: 5, Batch: 411, Loss: 0.0016320599243044853\n",
            "Epoch: 5, Batch: 421, Loss: 0.0029591454658657312\n",
            "Epoch: 5, Batch: 431, Loss: 0.004519238136708736\n",
            "Epoch: 5, Batch: 441, Loss: 0.003015212481841445\n",
            "Epoch: 5, Batch: 451, Loss: 0.0039455471560359\n",
            "Epoch: 5, Batch: 461, Loss: 0.007399703375995159\n",
            "Epoch: 5, Batch: 471, Loss: 0.002431764267385006\n",
            "Epoch: 5, Batch: 481, Loss: 0.003412316320464015\n",
            "Epoch: 5, Batch: 491, Loss: 0.0021749818697571754\n",
            "Epoch: 5, Batch: 501, Loss: 0.0014331171987578273\n",
            "Epoch: 5, Batch: 511, Loss: 0.0014230289962142706\n",
            "Epoch: 5, Batch: 521, Loss: 0.0017543842550367117\n",
            "Epoch: 5, Batch: 531, Loss: 0.0016561311203986406\n",
            "Epoch: 5, Batch: 541, Loss: 0.0036665727384388447\n",
            "Epoch: 5, Batch: 551, Loss: 0.0062273298390209675\n",
            "Epoch: 5, Batch: 561, Loss: 0.002828117460012436\n",
            "Epoch: 5, Batch: 571, Loss: 0.0027129917871207\n",
            "Epoch: 5, Batch: 581, Loss: 0.004895203746855259\n",
            "Epoch: 5, Batch: 591, Loss: 0.0033650631085038185\n",
            "Epoch: 5, Batch: 601, Loss: 0.003333513392135501\n",
            "Epoch: 5, Batch: 611, Loss: 0.004995930939912796\n",
            "Epoch: 5, Batch: 621, Loss: 0.0022383343894034624\n",
            "Epoch: 5, Batch: 631, Loss: 0.0023519438691437244\n",
            "Epoch: 5, Batch: 641, Loss: 0.002196249784901738\n",
            "Epoch: 5, Batch: 651, Loss: 0.0022904674988240004\n",
            "Epoch: 5, Batch: 661, Loss: 0.011083164252340794\n",
            "Epoch: 5, Batch: 671, Loss: 0.002719142008572817\n",
            "Epoch: 5, Batch: 681, Loss: 0.004519816488027573\n",
            "Epoch: 5, Batch: 691, Loss: 0.004686793312430382\n",
            "Epoch: 5, Batch: 701, Loss: 0.004129696171730757\n",
            "Epoch: 5, Batch: 711, Loss: 0.0030670850537717342\n",
            "Epoch: 5, Batch: 721, Loss: 0.0026138820685446262\n",
            "Epoch: 5, Batch: 731, Loss: 0.0026050277519971132\n",
            "Epoch: 5, Batch: 741, Loss: 0.0037657052744179964\n",
            "Epoch: 5, Batch: 751, Loss: 0.0022954042069613934\n",
            "Epoch: 5, Batch: 761, Loss: 0.00467838067561388\n",
            "Epoch: 5, Batch: 771, Loss: 0.0026169191114604473\n",
            "Epoch: 5, Batch: 781, Loss: 0.0018123118206858635\n",
            "Epoch: 5, Batch: 791, Loss: 0.003959050867706537\n",
            "Epoch: 5, Batch: 801, Loss: 0.0017528311582282186\n",
            "Epoch: 5, Batch: 811, Loss: 0.0018827413441613317\n",
            "Starting Epoch 6/10\n",
            "Epoch: 6, Batch: 1, Loss: 0.0027874833904206753\n",
            "Epoch: 6, Batch: 11, Loss: 0.00315177533775568\n",
            "Epoch: 6, Batch: 21, Loss: 0.002047585556283593\n",
            "Epoch: 6, Batch: 31, Loss: 0.001644869800657034\n",
            "Epoch: 6, Batch: 41, Loss: 0.002072322880849242\n",
            "Epoch: 6, Batch: 51, Loss: 0.0026193377561867237\n",
            "Epoch: 6, Batch: 61, Loss: 0.003616047091782093\n",
            "Epoch: 6, Batch: 71, Loss: 0.0018273801542818546\n",
            "Epoch: 6, Batch: 81, Loss: 0.004928157664835453\n",
            "Epoch: 6, Batch: 91, Loss: 0.0032337529119104147\n",
            "Epoch: 6, Batch: 101, Loss: 0.002188134705647826\n",
            "Epoch: 6, Batch: 111, Loss: 0.0016688336618244648\n",
            "Epoch: 6, Batch: 121, Loss: 0.0022993995808064938\n",
            "Epoch: 6, Batch: 131, Loss: 0.0022188618313521147\n",
            "Epoch: 6, Batch: 141, Loss: 0.0029794175643473864\n",
            "Epoch: 6, Batch: 151, Loss: 0.0014910654863342643\n",
            "Epoch: 6, Batch: 161, Loss: 0.0030574165284633636\n",
            "Epoch: 6, Batch: 171, Loss: 0.003198934718966484\n",
            "Epoch: 6, Batch: 181, Loss: 0.004202446900308132\n",
            "Epoch: 6, Batch: 191, Loss: 0.0031693417113274336\n",
            "Epoch: 6, Batch: 201, Loss: 0.005581975914537907\n",
            "Epoch: 6, Batch: 211, Loss: 0.005469537805765867\n",
            "Epoch: 6, Batch: 221, Loss: 0.0029465705156326294\n",
            "Epoch: 6, Batch: 231, Loss: 0.002210418926551938\n",
            "Epoch: 6, Batch: 241, Loss: 0.0033542129676789045\n",
            "Epoch: 6, Batch: 251, Loss: 0.0018037904519587755\n",
            "Epoch: 6, Batch: 261, Loss: 0.0017894639167934656\n",
            "Epoch: 6, Batch: 271, Loss: 0.00448059756308794\n",
            "Epoch: 6, Batch: 281, Loss: 0.0017741245683282614\n",
            "Epoch: 6, Batch: 291, Loss: 0.0018257074989378452\n",
            "Epoch: 6, Batch: 301, Loss: 0.0019547664560377598\n",
            "Epoch: 6, Batch: 311, Loss: 0.004093468189239502\n",
            "Epoch: 6, Batch: 321, Loss: 0.0043745203875005245\n",
            "Epoch: 6, Batch: 331, Loss: 0.0022287035826593637\n",
            "Epoch: 6, Batch: 341, Loss: 0.004991916473954916\n",
            "Epoch: 6, Batch: 351, Loss: 0.0026717742439359426\n",
            "Epoch: 6, Batch: 361, Loss: 0.0014455551281571388\n",
            "Epoch: 6, Batch: 371, Loss: 0.0017524311551824212\n",
            "Epoch: 6, Batch: 381, Loss: 0.006143980193883181\n",
            "Epoch: 6, Batch: 391, Loss: 0.002291478682309389\n",
            "Epoch: 6, Batch: 401, Loss: 0.001899167662486434\n",
            "Epoch: 6, Batch: 411, Loss: 0.0026541359256953\n",
            "Epoch: 6, Batch: 421, Loss: 0.0041396282613277435\n",
            "Epoch: 6, Batch: 431, Loss: 0.0024938415735960007\n",
            "Epoch: 6, Batch: 441, Loss: 0.001954235602170229\n",
            "Epoch: 6, Batch: 451, Loss: 0.0024531832896173\n",
            "Epoch: 6, Batch: 461, Loss: 0.002711827401071787\n",
            "Epoch: 6, Batch: 471, Loss: 0.003163488581776619\n",
            "Epoch: 6, Batch: 481, Loss: 0.0051827337592840195\n",
            "Epoch: 6, Batch: 491, Loss: 0.001789948670193553\n",
            "Epoch: 6, Batch: 501, Loss: 0.0030219710897654295\n",
            "Epoch: 6, Batch: 511, Loss: 0.0022973529994487762\n",
            "Epoch: 6, Batch: 521, Loss: 0.0023465987760573626\n",
            "Epoch: 6, Batch: 531, Loss: 0.0017285142093896866\n",
            "Epoch: 6, Batch: 541, Loss: 0.002668908564373851\n",
            "Epoch: 6, Batch: 551, Loss: 0.0023747808299958706\n",
            "Epoch: 6, Batch: 561, Loss: 0.0011589081259444356\n",
            "Epoch: 6, Batch: 571, Loss: 0.001036965986713767\n",
            "Epoch: 6, Batch: 581, Loss: 0.002783678937703371\n",
            "Epoch: 6, Batch: 591, Loss: 0.003961733542382717\n",
            "Epoch: 6, Batch: 601, Loss: 0.006526819430291653\n",
            "Epoch: 6, Batch: 611, Loss: 0.0011913494672626257\n",
            "Epoch: 6, Batch: 621, Loss: 0.002780339913442731\n",
            "Epoch: 6, Batch: 631, Loss: 0.0015262698289006948\n",
            "Epoch: 6, Batch: 641, Loss: 0.003011031076312065\n",
            "Epoch: 6, Batch: 651, Loss: 0.0030518691055476665\n",
            "Epoch: 6, Batch: 661, Loss: 0.0022595361806452274\n",
            "Epoch: 6, Batch: 671, Loss: 0.0035620713606476784\n",
            "Epoch: 6, Batch: 681, Loss: 0.004301297478377819\n",
            "Epoch: 6, Batch: 691, Loss: 0.004958762787282467\n",
            "Epoch: 6, Batch: 701, Loss: 0.0035874531604349613\n",
            "Epoch: 6, Batch: 711, Loss: 0.0017655736301094294\n",
            "Epoch: 6, Batch: 721, Loss: 0.004001962020993233\n",
            "Epoch: 6, Batch: 731, Loss: 0.00201726658269763\n",
            "Epoch: 6, Batch: 741, Loss: 0.002020576735958457\n",
            "Epoch: 6, Batch: 751, Loss: 0.003311786102131009\n",
            "Epoch: 6, Batch: 761, Loss: 0.0028601561207324266\n",
            "Epoch: 6, Batch: 771, Loss: 0.004247950855642557\n",
            "Epoch: 6, Batch: 781, Loss: 0.0014821323566138744\n",
            "Epoch: 6, Batch: 791, Loss: 0.006077996455132961\n",
            "Epoch: 6, Batch: 801, Loss: 0.0056978072971105576\n",
            "Epoch: 6, Batch: 811, Loss: 0.002613539807498455\n",
            "Starting Epoch 7/10\n",
            "Epoch: 7, Batch: 1, Loss: 0.005696683656424284\n",
            "Epoch: 7, Batch: 11, Loss: 0.003215076634660363\n",
            "Epoch: 7, Batch: 21, Loss: 0.003139065345749259\n",
            "Epoch: 7, Batch: 31, Loss: 0.0023617353290319443\n",
            "Epoch: 7, Batch: 41, Loss: 0.001704482245258987\n",
            "Epoch: 7, Batch: 51, Loss: 0.0024948688223958015\n",
            "Epoch: 7, Batch: 61, Loss: 0.001344002434052527\n",
            "Epoch: 7, Batch: 71, Loss: 0.0017084458377212286\n",
            "Epoch: 7, Batch: 81, Loss: 0.001518041710369289\n",
            "Epoch: 7, Batch: 91, Loss: 0.0024159764871001244\n",
            "Epoch: 7, Batch: 101, Loss: 0.001590078230947256\n",
            "Epoch: 7, Batch: 111, Loss: 0.0014400850050151348\n",
            "Epoch: 7, Batch: 121, Loss: 0.003094723913818598\n",
            "Epoch: 7, Batch: 131, Loss: 0.001644239411689341\n",
            "Epoch: 7, Batch: 141, Loss: 0.001106582465581596\n",
            "Epoch: 7, Batch: 151, Loss: 0.002357088727876544\n",
            "Epoch: 7, Batch: 161, Loss: 0.002258490538224578\n",
            "Epoch: 7, Batch: 171, Loss: 0.0024188884999603033\n",
            "Epoch: 7, Batch: 181, Loss: 0.00255692470818758\n",
            "Epoch: 7, Batch: 191, Loss: 0.0014059343375265598\n",
            "Epoch: 7, Batch: 201, Loss: 0.001019192859530449\n",
            "Epoch: 7, Batch: 211, Loss: 0.0014936875086277723\n",
            "Epoch: 7, Batch: 221, Loss: 0.0030014372896403074\n",
            "Epoch: 7, Batch: 231, Loss: 0.0019351225346326828\n",
            "Epoch: 7, Batch: 241, Loss: 0.004470011685043573\n",
            "Epoch: 7, Batch: 251, Loss: 0.004154379013925791\n",
            "Epoch: 7, Batch: 261, Loss: 0.0024971014354377985\n",
            "Epoch: 7, Batch: 271, Loss: 0.0021650895942002535\n",
            "Epoch: 7, Batch: 281, Loss: 0.0017508028540760279\n",
            "Epoch: 7, Batch: 291, Loss: 0.0024829355534166098\n",
            "Epoch: 7, Batch: 301, Loss: 0.0020873763132840395\n",
            "Epoch: 7, Batch: 311, Loss: 0.0012344277929514647\n",
            "Epoch: 7, Batch: 321, Loss: 0.002040982013568282\n",
            "Epoch: 7, Batch: 331, Loss: 0.002821768168359995\n",
            "Epoch: 7, Batch: 341, Loss: 0.0019081451464444399\n",
            "Epoch: 7, Batch: 351, Loss: 0.0024190451949834824\n",
            "Epoch: 7, Batch: 361, Loss: 0.003436850383877754\n",
            "Epoch: 7, Batch: 371, Loss: 0.0027667474932968616\n",
            "Epoch: 7, Batch: 381, Loss: 0.0011929660104215145\n",
            "Epoch: 7, Batch: 391, Loss: 0.0018828038591891527\n",
            "Epoch: 7, Batch: 401, Loss: 0.0017906324937939644\n",
            "Epoch: 7, Batch: 411, Loss: 0.001165676163509488\n",
            "Epoch: 7, Batch: 421, Loss: 0.005538828205317259\n",
            "Epoch: 7, Batch: 431, Loss: 0.0018463801825419068\n",
            "Epoch: 7, Batch: 441, Loss: 0.0026676971465349197\n",
            "Epoch: 7, Batch: 451, Loss: 0.003152495715767145\n",
            "Epoch: 7, Batch: 461, Loss: 0.006461376324295998\n",
            "Epoch: 7, Batch: 471, Loss: 0.0025615717750042677\n",
            "Epoch: 7, Batch: 481, Loss: 0.0013549566501751542\n",
            "Epoch: 7, Batch: 491, Loss: 0.006990905851125717\n",
            "Epoch: 7, Batch: 501, Loss: 0.003538658609613776\n",
            "Epoch: 7, Batch: 511, Loss: 0.0017073669005185366\n",
            "Epoch: 7, Batch: 521, Loss: 0.0025313720107078552\n",
            "Epoch: 7, Batch: 531, Loss: 0.0017913484480232\n",
            "Epoch: 7, Batch: 541, Loss: 0.003012540517374873\n",
            "Epoch: 7, Batch: 551, Loss: 0.0018891643267124891\n",
            "Epoch: 7, Batch: 561, Loss: 0.0023998869583010674\n",
            "Epoch: 7, Batch: 571, Loss: 0.0012413839576765895\n",
            "Epoch: 7, Batch: 581, Loss: 0.0012203410733491182\n",
            "Epoch: 7, Batch: 591, Loss: 0.0020183222368359566\n",
            "Epoch: 7, Batch: 601, Loss: 0.0019373423419892788\n",
            "Epoch: 7, Batch: 611, Loss: 0.002773093758150935\n",
            "Epoch: 7, Batch: 621, Loss: 0.0020934706553816795\n",
            "Epoch: 7, Batch: 631, Loss: 0.004130003973841667\n",
            "Epoch: 7, Batch: 641, Loss: 0.0017176155233755708\n",
            "Epoch: 7, Batch: 651, Loss: 0.0019886402878910303\n",
            "Epoch: 7, Batch: 661, Loss: 0.001637822249904275\n",
            "Epoch: 7, Batch: 671, Loss: 0.0028948127292096615\n",
            "Epoch: 7, Batch: 681, Loss: 0.004140776582062244\n",
            "Epoch: 7, Batch: 691, Loss: 0.0008777267066761851\n",
            "Epoch: 7, Batch: 701, Loss: 0.0030731752049177885\n",
            "Epoch: 7, Batch: 711, Loss: 0.0009625180391594768\n",
            "Epoch: 7, Batch: 721, Loss: 0.002986424369737506\n",
            "Epoch: 7, Batch: 731, Loss: 0.0022449162788689137\n",
            "Epoch: 7, Batch: 741, Loss: 0.0024075761903077364\n",
            "Epoch: 7, Batch: 751, Loss: 0.0034481326583772898\n",
            "Epoch: 7, Batch: 761, Loss: 0.001435757614672184\n",
            "Epoch: 7, Batch: 771, Loss: 0.0013276883400976658\n",
            "Epoch: 7, Batch: 781, Loss: 0.0031309037003666162\n",
            "Epoch: 7, Batch: 791, Loss: 0.0015459253918379545\n",
            "Epoch: 7, Batch: 801, Loss: 0.002183332573622465\n",
            "Epoch: 7, Batch: 811, Loss: 0.002851655939593911\n",
            "Starting Epoch 8/10\n",
            "Epoch: 8, Batch: 1, Loss: 0.0009522412437945604\n",
            "Epoch: 8, Batch: 11, Loss: 0.0015262477099895477\n",
            "Epoch: 8, Batch: 21, Loss: 0.0030349702574312687\n",
            "Epoch: 8, Batch: 31, Loss: 0.002666780026629567\n",
            "Epoch: 8, Batch: 41, Loss: 0.001991753466427326\n",
            "Epoch: 8, Batch: 51, Loss: 0.003113671438768506\n",
            "Epoch: 8, Batch: 61, Loss: 0.0018666723044589162\n",
            "Epoch: 8, Batch: 71, Loss: 0.0015676789917051792\n",
            "Epoch: 8, Batch: 81, Loss: 0.0009573752759024501\n",
            "Epoch: 8, Batch: 91, Loss: 0.003298109630122781\n",
            "Epoch: 8, Batch: 101, Loss: 0.001811942202039063\n",
            "Epoch: 8, Batch: 111, Loss: 0.0019344112370163202\n",
            "Epoch: 8, Batch: 121, Loss: 0.002796107903122902\n",
            "Epoch: 8, Batch: 131, Loss: 0.002204494783654809\n",
            "Epoch: 8, Batch: 141, Loss: 0.004681703168898821\n",
            "Epoch: 8, Batch: 151, Loss: 0.0007490729331038892\n",
            "Epoch: 8, Batch: 161, Loss: 0.0013537531485781074\n",
            "Epoch: 8, Batch: 171, Loss: 0.0025426491629332304\n",
            "Epoch: 8, Batch: 181, Loss: 0.0027082948945462704\n",
            "Epoch: 8, Batch: 191, Loss: 0.0009626698447391391\n",
            "Epoch: 8, Batch: 201, Loss: 0.002024552319198847\n",
            "Epoch: 8, Batch: 211, Loss: 0.0022355960682034492\n",
            "Epoch: 8, Batch: 221, Loss: 0.006066611502319574\n",
            "Epoch: 8, Batch: 231, Loss: 0.001078248955309391\n",
            "Epoch: 8, Batch: 241, Loss: 0.0012898119166493416\n",
            "Epoch: 8, Batch: 251, Loss: 0.001265765749849379\n",
            "Epoch: 8, Batch: 261, Loss: 0.002176106907427311\n",
            "Epoch: 8, Batch: 271, Loss: 0.0013620901154354215\n",
            "Epoch: 8, Batch: 281, Loss: 0.0018891599029302597\n",
            "Epoch: 8, Batch: 291, Loss: 0.0016760684084147215\n",
            "Epoch: 8, Batch: 301, Loss: 0.0015015762764960527\n",
            "Epoch: 8, Batch: 311, Loss: 0.0009374983492307365\n",
            "Epoch: 8, Batch: 321, Loss: 0.0013148405123502016\n",
            "Epoch: 8, Batch: 331, Loss: 0.0017417636699974537\n",
            "Epoch: 8, Batch: 341, Loss: 0.004292929079383612\n",
            "Epoch: 8, Batch: 351, Loss: 0.0023602230940014124\n",
            "Epoch: 8, Batch: 361, Loss: 0.0013675533700734377\n",
            "Epoch: 8, Batch: 371, Loss: 0.005308810621500015\n",
            "Epoch: 8, Batch: 381, Loss: 0.0029898989014327526\n",
            "Epoch: 8, Batch: 391, Loss: 0.0019573583267629147\n",
            "Epoch: 8, Batch: 401, Loss: 0.0008937071543186903\n",
            "Epoch: 8, Batch: 411, Loss: 0.0027882633730769157\n",
            "Epoch: 8, Batch: 421, Loss: 0.0018780188402161002\n",
            "Epoch: 8, Batch: 431, Loss: 0.002681997837498784\n",
            "Epoch: 8, Batch: 441, Loss: 0.001989568816497922\n",
            "Epoch: 8, Batch: 451, Loss: 0.003348778700456023\n",
            "Epoch: 8, Batch: 461, Loss: 0.0019450029358267784\n",
            "Epoch: 8, Batch: 471, Loss: 0.002449582563713193\n",
            "Epoch: 8, Batch: 481, Loss: 0.0013540938962250948\n",
            "Epoch: 8, Batch: 491, Loss: 0.002922899555414915\n",
            "Epoch: 8, Batch: 501, Loss: 0.0015355056384578347\n",
            "Epoch: 8, Batch: 511, Loss: 0.0029120640829205513\n",
            "Epoch: 8, Batch: 521, Loss: 0.0043039470911026\n",
            "Epoch: 8, Batch: 531, Loss: 0.00224106851965189\n",
            "Epoch: 8, Batch: 541, Loss: 0.002592751057818532\n",
            "Epoch: 8, Batch: 551, Loss: 0.0011273190611973405\n",
            "Epoch: 8, Batch: 561, Loss: 0.0033133085817098618\n",
            "Epoch: 8, Batch: 571, Loss: 0.004026039503514767\n",
            "Epoch: 8, Batch: 581, Loss: 0.0007906884420663118\n",
            "Epoch: 8, Batch: 591, Loss: 0.002064596861600876\n",
            "Epoch: 8, Batch: 601, Loss: 0.0021895132958889008\n",
            "Epoch: 8, Batch: 611, Loss: 0.0012128124944865704\n",
            "Epoch: 8, Batch: 621, Loss: 0.0020561537239700556\n",
            "Epoch: 8, Batch: 631, Loss: 0.003489485941827297\n",
            "Epoch: 8, Batch: 641, Loss: 0.002814042614772916\n",
            "Epoch: 8, Batch: 651, Loss: 0.0007813302217982709\n",
            "Epoch: 8, Batch: 661, Loss: 0.0032075210474431515\n",
            "Epoch: 8, Batch: 671, Loss: 0.008289029821753502\n",
            "Epoch: 8, Batch: 681, Loss: 0.0015484229661524296\n",
            "Epoch: 8, Batch: 691, Loss: 0.004055044148117304\n",
            "Epoch: 8, Batch: 701, Loss: 0.00439653592184186\n",
            "Epoch: 8, Batch: 711, Loss: 0.0012428557965904474\n",
            "Epoch: 8, Batch: 721, Loss: 0.001979774795472622\n",
            "Epoch: 8, Batch: 731, Loss: 0.002715575508773327\n",
            "Epoch: 8, Batch: 741, Loss: 0.0018600859912112355\n",
            "Epoch: 8, Batch: 751, Loss: 0.002356340177357197\n",
            "Epoch: 8, Batch: 761, Loss: 0.0021183579228818417\n",
            "Epoch: 8, Batch: 771, Loss: 0.003335526678711176\n",
            "Epoch: 8, Batch: 781, Loss: 0.0013392589753493667\n",
            "Epoch: 8, Batch: 791, Loss: 0.0016932752914726734\n",
            "Epoch: 8, Batch: 801, Loss: 0.00438920920714736\n",
            "Epoch: 8, Batch: 811, Loss: 0.0013732252409681678\n",
            "Starting Epoch 9/10\n",
            "Epoch: 9, Batch: 1, Loss: 0.000939179677516222\n",
            "Epoch: 9, Batch: 11, Loss: 0.0026545668952167034\n",
            "Epoch: 9, Batch: 21, Loss: 0.003786120330914855\n",
            "Epoch: 9, Batch: 31, Loss: 0.001114168670028448\n",
            "Epoch: 9, Batch: 41, Loss: 0.00545111857354641\n",
            "Epoch: 9, Batch: 51, Loss: 0.0010744092287495732\n",
            "Epoch: 9, Batch: 61, Loss: 0.0010425233049318194\n",
            "Epoch: 9, Batch: 71, Loss: 0.0011185258626937866\n",
            "Epoch: 9, Batch: 81, Loss: 0.003896447829902172\n",
            "Epoch: 9, Batch: 91, Loss: 0.002451034728437662\n",
            "Epoch: 9, Batch: 101, Loss: 0.0016117552295327187\n",
            "Epoch: 9, Batch: 111, Loss: 0.0015314918709918857\n",
            "Epoch: 9, Batch: 121, Loss: 0.0013488370459526777\n",
            "Epoch: 9, Batch: 131, Loss: 0.0015669988933950663\n",
            "Epoch: 9, Batch: 141, Loss: 0.0024617058224976063\n",
            "Epoch: 9, Batch: 151, Loss: 0.0019270011689513922\n",
            "Epoch: 9, Batch: 161, Loss: 0.0049356212839484215\n",
            "Epoch: 9, Batch: 171, Loss: 0.0020445508416742086\n",
            "Epoch: 9, Batch: 181, Loss: 0.003958032466471195\n",
            "Epoch: 9, Batch: 191, Loss: 0.0014197621494531631\n",
            "Epoch: 9, Batch: 201, Loss: 0.0013254756340757012\n",
            "Epoch: 9, Batch: 211, Loss: 0.0011065301951020956\n",
            "Epoch: 9, Batch: 221, Loss: 0.0028569158166646957\n",
            "Epoch: 9, Batch: 231, Loss: 0.0012427091132849455\n",
            "Epoch: 9, Batch: 241, Loss: 0.005309853702783585\n",
            "Epoch: 9, Batch: 251, Loss: 0.0026112764608114958\n",
            "Epoch: 9, Batch: 261, Loss: 0.0018457616679370403\n",
            "Epoch: 9, Batch: 271, Loss: 0.0009929456282407045\n",
            "Epoch: 9, Batch: 281, Loss: 0.002398535143584013\n",
            "Epoch: 9, Batch: 291, Loss: 0.00464244419708848\n",
            "Epoch: 9, Batch: 301, Loss: 0.0014725551009178162\n",
            "Epoch: 9, Batch: 311, Loss: 0.001873703207820654\n",
            "Epoch: 9, Batch: 321, Loss: 0.001012536697089672\n",
            "Epoch: 9, Batch: 331, Loss: 0.0029534955974668264\n",
            "Epoch: 9, Batch: 341, Loss: 0.002178365830332041\n",
            "Epoch: 9, Batch: 351, Loss: 0.001404947368428111\n",
            "Epoch: 9, Batch: 361, Loss: 0.0053122201934456825\n",
            "Epoch: 9, Batch: 371, Loss: 0.0008380291401408613\n",
            "Epoch: 9, Batch: 381, Loss: 0.0010636418592184782\n",
            "Epoch: 9, Batch: 391, Loss: 0.003238942474126816\n",
            "Epoch: 9, Batch: 401, Loss: 0.002102052327245474\n",
            "Epoch: 9, Batch: 411, Loss: 0.0026812925934791565\n",
            "Epoch: 9, Batch: 421, Loss: 0.0013596804346889257\n",
            "Epoch: 9, Batch: 431, Loss: 0.0022008181549608707\n",
            "Epoch: 9, Batch: 441, Loss: 0.001757966703735292\n",
            "Epoch: 9, Batch: 451, Loss: 0.0018876001704484224\n",
            "Epoch: 9, Batch: 461, Loss: 0.00204989081248641\n",
            "Epoch: 9, Batch: 471, Loss: 0.003236208576709032\n",
            "Epoch: 9, Batch: 481, Loss: 0.0016570911975577474\n",
            "Epoch: 9, Batch: 491, Loss: 0.0013563171960413456\n",
            "Epoch: 9, Batch: 501, Loss: 0.002410722430795431\n",
            "Epoch: 9, Batch: 511, Loss: 0.0017611688235774636\n",
            "Epoch: 9, Batch: 521, Loss: 0.0025868022348731756\n",
            "Epoch: 9, Batch: 531, Loss: 0.0024185986258089542\n",
            "Epoch: 9, Batch: 541, Loss: 0.0016883439384400845\n",
            "Epoch: 9, Batch: 551, Loss: 0.0010747355408966541\n",
            "Epoch: 9, Batch: 561, Loss: 0.003818281926214695\n",
            "Epoch: 9, Batch: 571, Loss: 0.0013106662081554532\n",
            "Epoch: 9, Batch: 581, Loss: 0.0011808566050603986\n",
            "Epoch: 9, Batch: 591, Loss: 0.004242873750627041\n",
            "Epoch: 9, Batch: 601, Loss: 0.005648576654493809\n",
            "Epoch: 9, Batch: 611, Loss: 0.002696209354326129\n",
            "Epoch: 9, Batch: 621, Loss: 0.002935166470706463\n",
            "Epoch: 9, Batch: 631, Loss: 0.008148252964019775\n",
            "Epoch: 9, Batch: 641, Loss: 0.001976697938516736\n",
            "Epoch: 9, Batch: 651, Loss: 0.0020178486593067646\n",
            "Epoch: 9, Batch: 661, Loss: 0.0042195189744234085\n",
            "Epoch: 9, Batch: 671, Loss: 0.0022277669049799442\n",
            "Epoch: 9, Batch: 681, Loss: 0.002433848101645708\n",
            "Epoch: 9, Batch: 691, Loss: 0.0010459902696311474\n",
            "Epoch: 9, Batch: 701, Loss: 0.001462235813960433\n",
            "Epoch: 9, Batch: 711, Loss: 0.0011012557661160827\n",
            "Epoch: 9, Batch: 721, Loss: 0.0037323429714888334\n",
            "Epoch: 9, Batch: 731, Loss: 0.0016915731830522418\n",
            "Epoch: 9, Batch: 741, Loss: 0.0020733291748911142\n",
            "Epoch: 9, Batch: 751, Loss: 0.0018693922320380807\n",
            "Epoch: 9, Batch: 761, Loss: 0.0008715398726053536\n",
            "Epoch: 9, Batch: 771, Loss: 0.0024432106874883175\n",
            "Epoch: 9, Batch: 781, Loss: 0.002722862409427762\n",
            "Epoch: 9, Batch: 791, Loss: 0.0027836475055664778\n",
            "Epoch: 9, Batch: 801, Loss: 0.0016037776367738843\n",
            "Epoch: 9, Batch: 811, Loss: 0.002342217369005084\n",
            "Starting Epoch 10/10\n",
            "Epoch: 10, Batch: 1, Loss: 0.001347630051895976\n",
            "Epoch: 10, Batch: 11, Loss: 0.001470607123337686\n",
            "Epoch: 10, Batch: 21, Loss: 0.002031260635703802\n",
            "Epoch: 10, Batch: 31, Loss: 0.00391207542270422\n",
            "Epoch: 10, Batch: 41, Loss: 0.00243977177888155\n",
            "Epoch: 10, Batch: 51, Loss: 0.00200598849914968\n",
            "Epoch: 10, Batch: 61, Loss: 0.0024611458647996187\n",
            "Epoch: 10, Batch: 71, Loss: 0.0024248629342764616\n",
            "Epoch: 10, Batch: 81, Loss: 0.0018345658900216222\n",
            "Epoch: 10, Batch: 91, Loss: 0.0024817143566906452\n",
            "Epoch: 10, Batch: 101, Loss: 0.0030897215474396944\n",
            "Epoch: 10, Batch: 111, Loss: 0.0020374013110995293\n",
            "Epoch: 10, Batch: 121, Loss: 0.002577484818175435\n",
            "Epoch: 10, Batch: 131, Loss: 0.0011166463373228908\n",
            "Epoch: 10, Batch: 141, Loss: 0.004201639909297228\n",
            "Epoch: 10, Batch: 151, Loss: 0.001710065407678485\n",
            "Epoch: 10, Batch: 161, Loss: 0.0019093959126621485\n",
            "Epoch: 10, Batch: 171, Loss: 0.0019944608211517334\n",
            "Epoch: 10, Batch: 181, Loss: 0.002371915616095066\n",
            "Epoch: 10, Batch: 191, Loss: 0.003327791579067707\n",
            "Epoch: 10, Batch: 201, Loss: 0.0029373716097325087\n",
            "Epoch: 10, Batch: 211, Loss: 0.00327928364276886\n",
            "Epoch: 10, Batch: 221, Loss: 0.0037782376166433096\n",
            "Epoch: 10, Batch: 231, Loss: 0.0015604314394295216\n",
            "Epoch: 10, Batch: 241, Loss: 0.0017639582511037588\n",
            "Epoch: 10, Batch: 251, Loss: 0.003302296157926321\n",
            "Epoch: 10, Batch: 261, Loss: 0.0021856497041881084\n",
            "Epoch: 10, Batch: 271, Loss: 0.0019848933443427086\n",
            "Epoch: 10, Batch: 281, Loss: 0.0017527027521282434\n",
            "Epoch: 10, Batch: 291, Loss: 0.0059159803204238415\n",
            "Epoch: 10, Batch: 301, Loss: 0.002418301533907652\n",
            "Epoch: 10, Batch: 311, Loss: 0.0015912256203591824\n",
            "Epoch: 10, Batch: 321, Loss: 0.0019914633594453335\n",
            "Epoch: 10, Batch: 331, Loss: 0.0016117615159600973\n",
            "Epoch: 10, Batch: 341, Loss: 0.0018107359064742923\n",
            "Epoch: 10, Batch: 351, Loss: 0.002603858709335327\n",
            "Epoch: 10, Batch: 361, Loss: 0.001649008714593947\n",
            "Epoch: 10, Batch: 371, Loss: 0.001981575507670641\n",
            "Epoch: 10, Batch: 381, Loss: 0.0007809194503352046\n",
            "Epoch: 10, Batch: 391, Loss: 0.0009543842170387506\n",
            "Epoch: 10, Batch: 401, Loss: 0.001618489739485085\n",
            "Epoch: 10, Batch: 411, Loss: 0.007203508168458939\n",
            "Epoch: 10, Batch: 421, Loss: 0.003245518309995532\n",
            "Epoch: 10, Batch: 431, Loss: 0.00245928973890841\n",
            "Epoch: 10, Batch: 441, Loss: 0.0027039984706789255\n",
            "Epoch: 10, Batch: 451, Loss: 0.0054662493057549\n",
            "Epoch: 10, Batch: 461, Loss: 0.0016636669170111418\n",
            "Epoch: 10, Batch: 471, Loss: 0.0034606605768203735\n",
            "Epoch: 10, Batch: 481, Loss: 0.004082405939698219\n",
            "Epoch: 10, Batch: 491, Loss: 0.0019014838617295027\n",
            "Epoch: 10, Batch: 501, Loss: 0.006058832630515099\n",
            "Epoch: 10, Batch: 511, Loss: 0.0016006343066692352\n",
            "Epoch: 10, Batch: 521, Loss: 0.0026634279638528824\n",
            "Epoch: 10, Batch: 531, Loss: 0.0018494004616513848\n",
            "Epoch: 10, Batch: 541, Loss: 0.0012706733541563153\n",
            "Epoch: 10, Batch: 551, Loss: 0.001199571299366653\n",
            "Epoch: 10, Batch: 561, Loss: 0.003030175343155861\n",
            "Epoch: 10, Batch: 571, Loss: 0.001293135341256857\n",
            "Epoch: 10, Batch: 581, Loss: 0.003407163079828024\n",
            "Epoch: 10, Batch: 591, Loss: 0.002309724222868681\n",
            "Epoch: 10, Batch: 601, Loss: 0.0024902853183448315\n",
            "Epoch: 10, Batch: 611, Loss: 0.0024340851232409477\n",
            "Epoch: 10, Batch: 621, Loss: 0.010753381997346878\n",
            "Epoch: 10, Batch: 631, Loss: 0.0044118911027908325\n",
            "Epoch: 10, Batch: 641, Loss: 0.003010604763403535\n",
            "Epoch: 10, Batch: 651, Loss: 0.003944441210478544\n",
            "Epoch: 10, Batch: 661, Loss: 0.0020029384177178144\n",
            "Epoch: 10, Batch: 671, Loss: 0.013560501858592033\n",
            "Epoch: 10, Batch: 681, Loss: 0.0019024517387151718\n",
            "Epoch: 10, Batch: 691, Loss: 0.0027450411580502987\n",
            "Epoch: 10, Batch: 701, Loss: 0.0018288686405867338\n",
            "Epoch: 10, Batch: 711, Loss: 0.0024236084427684546\n",
            "Epoch: 10, Batch: 721, Loss: 0.0014263773337006569\n",
            "Epoch: 10, Batch: 731, Loss: 0.001973147038370371\n",
            "Epoch: 10, Batch: 741, Loss: 0.0040095797739923\n",
            "Epoch: 10, Batch: 751, Loss: 0.0033339380752295256\n",
            "Epoch: 10, Batch: 761, Loss: 0.00247262604534626\n",
            "Epoch: 10, Batch: 771, Loss: 0.0034301874693483114\n",
            "Epoch: 10, Batch: 781, Loss: 0.001635222346521914\n",
            "Epoch: 10, Batch: 791, Loss: 0.002178313210606575\n",
            "Epoch: 10, Batch: 801, Loss: 0.002308848313987255\n",
            "Epoch: 10, Batch: 811, Loss: 0.0025909473188221455\n",
            "Training finished!\n"
          ]
        }
      ]
    }
  ]
}